{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word level language model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMh4zxRqujXWLfxwW76ji1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alihassan7726/Language-Models/blob/main/Word_level_language_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2S7K18YqAls"
      },
      "source": [
        "#### I've cleaned and transformed the text in seperate file \" Word level language model using GloVe\" . I'll be importing the same cleaned data to build a model .  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4u9GVoSps5E",
        "outputId": "87f1f7d8-0aa2-4826-db6d-aa505d449043"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zds-Hg_zp7Jg",
        "outputId": "b9b51f12-bbd7-4df0-9ed2-5f90d8206cfd"
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = '/content/gdrive/MyDrive/Colab DataSets/socrates_sequences.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "lines[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['book i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was',\n",
              " 'i i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted',\n",
              " 'i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1mphKjkqsS9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoSm8AI1qzEO"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF9RKqbVq1ZR",
        "outputId": "acb01d66-d317-41e2-cdbe-d4a87c7681df"
      },
      "source": [
        "word_index=tokenizer.word_index\n",
        "vocab_size = len(word_index)+1\n",
        "print('Number of unique words:',vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique words: 7410\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_DimWaFssyb"
      },
      "source": [
        "from pickle import dump\n",
        "# saving the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXDhOgpxrBTc",
        "outputId": "fde275a9-a32e-4e76-cbe5-18e86eb2639f"
      },
      "source": [
        "# separate into input and output\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]\n",
        "\n",
        "# Splitting the Data\n",
        "# create train and validation sets\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "print('Train shape:', X_tr.shape, 'Val shape:', X_val.shape)\n",
        "del(X)\n",
        "del(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape: (106769, 50) Val shape: (11864, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWgjyisGrnUZ"
      },
      "source": [
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import *\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAdmSoa_rXqt",
        "outputId": "763c8267-a2db-41df-c5c7-919bacf70d54"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 250, input_length=seq_length))\n",
        "model.add(Bidirectional(LSTM(250,return_sequences=True)))\n",
        "model.add(LSTM(250))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "#Add loss function, metrics, optimizer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy']) \n",
        "\n",
        "#Adding callbacks\n",
        "mc=ModelCheckpoint('/content/gdrive/MyDrive/Colab Notebooks/best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True,verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 50, 250)           1852500   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 50, 500)           1002000   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 250)               751000    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 250)               62750     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7410)              1859910   \n",
            "=================================================================\n",
            "Total params: 5,528,160\n",
            "Trainable params: 5,528,160\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz8VDHIbsMSq",
        "outputId": "e04d062c-4fdf-441a-c01c-8aa0125e48b7"
      },
      "source": [
        "from time import time\n",
        "t = time()\n",
        "history = model.fit(X_tr , y_tr , batch_size=100 , epochs=50,\n",
        "                    validation_data=( X_val , y_val ),verbose=1,callbacks=[mc],\n",
        "                    )\n",
        "print(\"Total time taken to run : {} mins\".format(np.round((time()-t)/60,decimals = 2)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1068/1068 [==============================] - 66s 62ms/step - loss: 5.9655 - accuracy: 0.0906 - val_loss: 5.6587 - val_accuracy: 0.1166\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.11657, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 2/50\n",
            "1068/1068 [==============================] - 59s 56ms/step - loss: 5.4212 - accuracy: 0.1364 - val_loss: 5.5053 - val_accuracy: 0.1428\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.11657 to 0.14278, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 3/50\n",
            "1068/1068 [==============================] - 60s 56ms/step - loss: 5.1652 - accuracy: 0.1573 - val_loss: 5.4423 - val_accuracy: 0.1537\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.14278 to 0.15366, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 4/50\n",
            "1068/1068 [==============================] - 59s 56ms/step - loss: 4.9819 - accuracy: 0.1691 - val_loss: 5.4427 - val_accuracy: 0.1565\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.15366 to 0.15652, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 5/50\n",
            "1068/1068 [==============================] - 60s 57ms/step - loss: 4.8340 - accuracy: 0.1784 - val_loss: 5.4713 - val_accuracy: 0.1639\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.15652 to 0.16394, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 6/50\n",
            "1068/1068 [==============================] - 60s 56ms/step - loss: 4.7015 - accuracy: 0.1862 - val_loss: 5.5092 - val_accuracy: 0.1678\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.16394 to 0.16782, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 7/50\n",
            "1068/1068 [==============================] - 65s 60ms/step - loss: 4.5781 - accuracy: 0.1948 - val_loss: 5.6023 - val_accuracy: 0.1734\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.16782 to 0.17338, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 8/50\n",
            "1068/1068 [==============================] - 66s 62ms/step - loss: 4.4647 - accuracy: 0.2019 - val_loss: 5.6519 - val_accuracy: 0.1731\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.17338\n",
            "Epoch 9/50\n",
            "1068/1068 [==============================] - 65s 61ms/step - loss: 4.3525 - accuracy: 0.2105 - val_loss: 5.7536 - val_accuracy: 0.1748\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.17338 to 0.17481, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 10/50\n",
            "1068/1068 [==============================] - 61s 57ms/step - loss: 4.2456 - accuracy: 0.2152 - val_loss: 5.9180 - val_accuracy: 0.1716\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.17481\n",
            "Epoch 11/50\n",
            "1068/1068 [==============================] - 59s 55ms/step - loss: 4.1395 - accuracy: 0.2219 - val_loss: 6.0580 - val_accuracy: 0.1768\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.17481 to 0.17675, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 12/50\n",
            "1068/1068 [==============================] - 59s 55ms/step - loss: 4.0321 - accuracy: 0.2288 - val_loss: 6.2608 - val_accuracy: 0.1769\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.17675 to 0.17692, saving model to /content/gdrive/MyDrive/Colab Notebooks/best_model.h5\n",
            "Epoch 13/50\n",
            "1068/1068 [==============================] - 59s 56ms/step - loss: 3.9248 - accuracy: 0.2379 - val_loss: 6.3858 - val_accuracy: 0.1715\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.17692\n",
            "Epoch 14/50\n",
            "1068/1068 [==============================] - 59s 56ms/step - loss: 3.8230 - accuracy: 0.2458 - val_loss: 6.6975 - val_accuracy: 0.1707\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.17692\n",
            "Epoch 15/50\n",
            "1068/1068 [==============================] - 60s 56ms/step - loss: 3.7129 - accuracy: 0.2565 - val_loss: 6.9137 - val_accuracy: 0.1672\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.17692\n",
            "Epoch 16/50\n",
            "1068/1068 [==============================] - 62s 58ms/step - loss: 3.6046 - accuracy: 0.2677 - val_loss: 7.1531 - val_accuracy: 0.1665\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.17692\n",
            "Epoch 17/50\n",
            "1068/1068 [==============================] - 62s 58ms/step - loss: 3.5005 - accuracy: 0.2792 - val_loss: 7.4418 - val_accuracy: 0.1661\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.17692\n",
            "Epoch 18/50\n",
            "1068/1068 [==============================] - 62s 58ms/step - loss: 3.3977 - accuracy: 0.2926 - val_loss: 7.6939 - val_accuracy: 0.1644\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.17692\n",
            "Epoch 19/50\n",
            "1068/1068 [==============================] - 62s 58ms/step - loss: 3.2933 - accuracy: 0.3064 - val_loss: 7.9479 - val_accuracy: 0.1576\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.17692\n",
            "Epoch 20/50\n",
            "1068/1068 [==============================] - 61s 57ms/step - loss: 3.1930 - accuracy: 0.3196 - val_loss: 8.2093 - val_accuracy: 0.1585\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.17692\n",
            "Epoch 21/50\n",
            "1068/1068 [==============================] - 63s 59ms/step - loss: 3.0897 - accuracy: 0.3354 - val_loss: 8.5753 - val_accuracy: 0.1521\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.17692\n",
            "Epoch 22/50\n",
            "1068/1068 [==============================] - 65s 61ms/step - loss: 2.9853 - accuracy: 0.3520 - val_loss: 8.8363 - val_accuracy: 0.1501\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.17692\n",
            "Epoch 23/50\n",
            "1068/1068 [==============================] - 66s 62ms/step - loss: 2.8842 - accuracy: 0.3676 - val_loss: 9.2509 - val_accuracy: 0.1463\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.17692\n",
            "Epoch 24/50\n",
            "1068/1068 [==============================] - 68s 64ms/step - loss: 2.7831 - accuracy: 0.3857 - val_loss: 9.4819 - val_accuracy: 0.1454\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.17692\n",
            "Epoch 25/50\n",
            "1068/1068 [==============================] - 68s 64ms/step - loss: 2.6853 - accuracy: 0.4017 - val_loss: 9.8717 - val_accuracy: 0.1405\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.17692\n",
            "Epoch 26/50\n",
            "1068/1068 [==============================] - 68s 64ms/step - loss: 2.5914 - accuracy: 0.4180 - val_loss: 10.2190 - val_accuracy: 0.1411\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.17692\n",
            "Epoch 27/50\n",
            "1068/1068 [==============================] - 70s 65ms/step - loss: 2.5001 - accuracy: 0.4361 - val_loss: 10.4192 - val_accuracy: 0.1368\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.17692\n",
            "Epoch 28/50\n",
            "1068/1068 [==============================] - 67s 63ms/step - loss: 2.4001 - accuracy: 0.4539 - val_loss: 10.8061 - val_accuracy: 0.1373\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.17692\n",
            "Epoch 29/50\n",
            "1068/1068 [==============================] - 64s 60ms/step - loss: 2.3042 - accuracy: 0.4718 - val_loss: 11.1086 - val_accuracy: 0.1326\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.17692\n",
            "Epoch 30/50\n",
            "1068/1068 [==============================] - 63s 59ms/step - loss: 2.2096 - accuracy: 0.4927 - val_loss: 11.5487 - val_accuracy: 0.1295\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.17692\n",
            "Epoch 31/50\n",
            "1068/1068 [==============================] - 63s 59ms/step - loss: 2.1183 - accuracy: 0.5109 - val_loss: 11.8583 - val_accuracy: 0.1253\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.17692\n",
            "Epoch 32/50\n",
            "1068/1068 [==============================] - 64s 60ms/step - loss: 2.0267 - accuracy: 0.5292 - val_loss: 12.2396 - val_accuracy: 0.1237\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.17692\n",
            "Epoch 33/50\n",
            "1068/1068 [==============================] - 64s 60ms/step - loss: 1.9425 - accuracy: 0.5472 - val_loss: 12.7211 - val_accuracy: 0.1221\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.17692\n",
            "Epoch 34/50\n",
            "1068/1068 [==============================] - 64s 60ms/step - loss: 1.8576 - accuracy: 0.5643 - val_loss: 13.1152 - val_accuracy: 0.1210\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.17692\n",
            "Epoch 35/50\n",
            "1068/1068 [==============================] - 63s 59ms/step - loss: 1.7777 - accuracy: 0.5822 - val_loss: 13.3304 - val_accuracy: 0.1217\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.17692\n",
            "Epoch 36/50\n",
            "1068/1068 [==============================] - 64s 60ms/step - loss: 1.6949 - accuracy: 0.5995 - val_loss: 13.6948 - val_accuracy: 0.1188\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.17692\n",
            "Epoch 37/50\n",
            "1068/1068 [==============================] - 64s 60ms/step - loss: 1.6184 - accuracy: 0.6162 - val_loss: 14.0693 - val_accuracy: 0.1151\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.17692\n",
            "Epoch 38/50\n",
            "1068/1068 [==============================] - 64s 60ms/step - loss: 1.5427 - accuracy: 0.6338 - val_loss: 14.5686 - val_accuracy: 0.1164\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.17692\n",
            "Epoch 39/50\n",
            "1068/1068 [==============================] - 61s 57ms/step - loss: 1.4799 - accuracy: 0.6471 - val_loss: 14.9589 - val_accuracy: 0.1163\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.17692\n",
            "Epoch 40/50\n",
            "1068/1068 [==============================] - 60s 56ms/step - loss: 1.4106 - accuracy: 0.6640 - val_loss: 15.2558 - val_accuracy: 0.1063\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.17692\n",
            "Epoch 41/50\n",
            "1068/1068 [==============================] - 61s 57ms/step - loss: 1.3469 - accuracy: 0.6771 - val_loss: 15.7431 - val_accuracy: 0.1162\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.17692\n",
            "Epoch 42/50\n",
            "1068/1068 [==============================] - 60s 57ms/step - loss: 1.2869 - accuracy: 0.6909 - val_loss: 16.0801 - val_accuracy: 0.1142\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.17692\n",
            "Epoch 43/50\n",
            "1068/1068 [==============================] - 61s 57ms/step - loss: 1.2240 - accuracy: 0.7052 - val_loss: 16.5254 - val_accuracy: 0.1121\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.17692\n",
            "Epoch 44/50\n",
            "1068/1068 [==============================] - 61s 57ms/step - loss: 1.1683 - accuracy: 0.7181 - val_loss: 16.9502 - val_accuracy: 0.1076\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.17692\n",
            "Epoch 45/50\n",
            "1068/1068 [==============================] - 62s 58ms/step - loss: 1.1192 - accuracy: 0.7292 - val_loss: 17.2263 - val_accuracy: 0.1065\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.17692\n",
            "Epoch 46/50\n",
            "1068/1068 [==============================] - 62s 58ms/step - loss: 1.0650 - accuracy: 0.7426 - val_loss: 17.5901 - val_accuracy: 0.1055\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.17692\n",
            "Epoch 47/50\n",
            "1068/1068 [==============================] - 61s 57ms/step - loss: 1.0245 - accuracy: 0.7516 - val_loss: 18.0765 - val_accuracy: 0.1073\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.17692\n",
            "Epoch 48/50\n",
            "1068/1068 [==============================] - 61s 58ms/step - loss: 0.9905 - accuracy: 0.7577 - val_loss: 18.4890 - val_accuracy: 0.1064\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.17692\n",
            "Epoch 49/50\n",
            "1068/1068 [==============================] - 61s 57ms/step - loss: 0.9358 - accuracy: 0.7728 - val_loss: 18.7947 - val_accuracy: 0.1039\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.17692\n",
            "Epoch 50/50\n",
            "1068/1068 [==============================] - 62s 58ms/step - loss: 0.9005 - accuracy: 0.7800 - val_loss: 19.3155 - val_accuracy: 0.1064\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.17692\n",
            "Total time taken to run : 52.37 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pky2It7ovhjp"
      },
      "source": [
        "## Saving current model instead of using previous model\n",
        "model.save('Final_model_socorates.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuYKpEXURRSn"
      },
      "source": [
        "# load doc into memory for testing\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = '/content/gdrive/MyDrive/Colab DataSets/socrates_sequences.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oqYHL0yRXhZ"
      },
      "source": [
        "seq_length = len(lines[0].split()) - 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPnxwYIeR-nG",
        "outputId": "db8c8c4f-4a62-4cb6-9cfa-f5b97a7ea9ae"
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "# load the model\n",
        "model_2 = load_model('Final_model_socorates.h5')\n",
        "# load the tokenizer\n",
        "tokenizer_2 = load(open('tokenizer.pkl', 'rb'))\n",
        "\n",
        "# Selecting a random seed text\n",
        "seed_text = lines[randint(0,len(lines))]\n",
        "print(seed_text + '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that from the individual they pass into the state how else can they come there take the quality of passion or spirit it would be ridiculous to imagine that this quality when found in states is not derived from the individuals who are supposed to possess it eg the thracians scythians\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SDu6QNdScPo"
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPHGDNk1Tm_x",
        "outputId": "3dc4586d-bde1-4dd2-898e-c33fa1a8eff8"
      },
      "source": [
        "# generate new text\n",
        "generated = generate_seq(model_2, tokenizer_2, seq_length, seed_text, 50)\n",
        "print(generated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "and and goes blinking for the offices of which the oligarchy is so incredulous and virtue and which every value has enumerated among the oaks of the rocks and cherisher of every sort of knowledge but vice and children are their brothers he said nor are they mind about the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Lx3ngiTwhr",
        "outputId": "2ed29be2-9fb6-4a60-a8fd-9fe0f9c1a15d"
      },
      "source": [
        "print(seed_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that from the individual they pass into the state how else can they come there take the quality of passion or spirit it would be ridiculous to imagine that this quality when found in states is not derived from the individuals who are supposed to possess it eg the thracians scythians\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JsGwUyZUdq_",
        "outputId": "43b0ff31-559f-42d3-8ebe-07b4c0a41b87"
      },
      "source": [
        "generated = generate_seq(model_2, tokenizer_2, seq_length, seed_text, 1)\n",
        "print(generated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "and\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PXxQI9kUyOv",
        "outputId": "e7ce9e33-ae69-4a58-99a8-a436f12e8b4d"
      },
      "source": [
        "## Another example\n",
        "seed_text = lines[randint(0,len(lines))]\n",
        "generated = generate_seq(model_2, tokenizer_2, seq_length, seed_text, 50)\n",
        "print(generated)\n",
        "print(seed_text , '...' , generated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "they are the counterpart of men of health still supplying faculties many and fair to them that will be his meaning he said then socrates in this stage of the slights which you propose before in this particular state there are tyrannies and this is said to have similar qualities\n",
            "or subjectmatter of knowledge and knowledge is to know the nature of being yes and opinion is to have an opinion yes and do we know what we opine or is the subjectmatter of opinion the same as the subjectmatter of knowledge nay he replied that has been already disproven if ... they are the counterpart of men of health still supplying faculties many and fair to them that will be his meaning he said then socrates in this stage of the slights which you propose before in this particular state there are tyrannies and this is said to have similar qualities\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp2DEfJ7VG4a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}